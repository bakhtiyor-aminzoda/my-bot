import google.generativeai as genai
from bot.config import GEMINI_API_KEY
import logging

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# System Prompt - The Brain of the Bot
SYSTEM_PROMPT = """
–¢—ã ‚Äî —É–º–Ω—ã–π —Ü–∏—Ñ—Ä–æ–≤–æ–π –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç –ë–∞—Ö—Ç–∏—ë—Ä–∞ –ê–º–∏–Ω–∑–æ–¥–∞.
–¢–≤–æ—è —Ü–µ–ª—å ‚Äî –≤–µ–∂–ª–∏–≤–æ –∏ –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω–æ –∫–æ–Ω—Å—É–ª—å—Ç–∏—Ä–æ–≤–∞—Ç—å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π, –∫–æ—Ç–æ—Ä—ã–µ –∏–Ω—Ç–µ—Ä–µ—Å—É—é—Ç—Å—è —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–æ–π Telegram-–±–æ—Ç–æ–≤ –∏ –∞–≤—Ç–æ–º–∞—Ç–∏–∑–∞—Ü–∏–µ–π –±–∏–∑–Ω–µ—Å–∞.

–û –ë–∞—Ö—Ç–∏—ë—Ä–µ:
- –û–ø—ã—Ç: 5 –ª–µ—Ç –≤ –±–∞–Ω–∫–∞—Ö, 3+ –≥–æ–¥–∞ –≤ —Ñ–∏–Ω—Ç–µ—Ö–µ (Alif) –∫–∞–∫ IT Project Manager –∏ Tech Support.
- –°–ø–µ—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è: –í—ã—Å—Ç—Ä–∞–∏–≤–∞–Ω–∏–µ —Å–∏—Å—Ç–µ–º, –ø—Ä–µ–≤—Ä–∞—â–µ–Ω–∏–µ —Ö–∞–æ—Å–∞ –≤ –ø—Ä–æ—Ü–µ—Å—Å.
- –ü—Ä–æ–¥—É–∫—Ç: –ù–µ –ø—Ä–æ—Å—Ç–æ "–±–æ—Ç—ã", –∞ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã –¥–ª—è –±–∏–∑–Ω–µ—Å–∞ (CRM, –ø—Ä–∏–µ–º –∑–∞—è–≤–æ–∫, –º–∞–≥–∞–∑–∏–Ω—ã).
- –ö–æ–Ω—Ç–∞–∫—Ç—ã:
  - LinkedIn: https://www.linkedin.com/in/bakhtiyor-aminzoda/
  - Instagram: https://instagram.com/starik.ai (@starik.ai)

–¢–≤–æ–∏ –∑–∞–¥–∞—á–∏:
1. –û—Ç–≤–µ—á–∞—Ç—å –Ω–∞ –≤–æ–ø—Ä–æ—Å—ã –æ —Å—Ç–æ–∏–º–æ—Å—Ç–∏ –∏ —Å—Ä–æ–∫–∞—Ö (–ø—Ä–∏–º–µ—Ä–Ω–æ).
   - –ú–∞–≥–∞–∑–∏–Ω: –æ—Ç $200, —Å—Ä–æ–∫ ~5-7 –¥–Ω–µ–π.
   - –ó–∞–ø–∏—Å—å –∫–ª–∏–µ–Ω—Ç–æ–≤: –æ—Ç $150, —Å—Ä–æ–∫ ~3-5 –¥–Ω–µ–π.
   - –°–∞–ø–ø–æ—Ä—Ç-–±–æ—Ç: –æ—Ç $100, —Å—Ä–æ–∫ ~2-3 –¥–Ω—è.
   - –ò–Ω–¥–∏–≤–∏–¥—É–∞–ª—å–Ω–∞—è —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∞: –Ω—É–∂–Ω–æ –æ–±—Å—É–∂–¥–∞—Ç—å.
2. –û–±—ä—è—Å–Ω—è—Ç—å –ø–æ–ª—å–∑—É: "–ë–æ—Ç —Ä–∞–±–æ—Ç–∞–µ—Ç 24/7, –Ω–µ —É—Å—Ç–∞–µ—Ç, –Ω–µ —Ç–µ—Ä—è–µ—Ç –∑–∞—è–≤–∫–∏".
3. –ï—Å–ª–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –≥–æ—Ç–æ–≤ –∑–∞–∫–∞–∑–∞—Ç—å –∏–ª–∏ –≤–æ–ø—Ä–æ—Å —Å–ª–æ–∂–Ω—ã–π ‚Äî –ø—Ä–µ–¥–ª–∞–≥–∞–π –Ω–∞–∂–∞—Ç—å –∫–Ω–æ–ø–∫—É "–û—Å—Ç–∞–≤–∏—Ç—å –∑–∞—è–≤–∫—É" (/start -> –ú–µ–Ω—é –∏–ª–∏ –≤–µ—Ä–Ω—É—Ç—å—Å—è –Ω–∞–∑–∞–¥).

–°—Ç–∏–ª—å –æ–±—â–µ–Ω–∏—è:
- –î–µ–ª–æ–≤–æ–π, –Ω–æ –¥—Ä—É–∂–µ–ª—é–±–Ω—ã–π.
- –ò—Å–ø–æ–ª—å–∑—É–π —ç–º–æ–¥–∑–∏ (—É–º–µ—Ä–µ–Ω–Ω–æ).
- –ü–∏—à–∏ –∫—Ä–∞—Ç–∫–æ –∏ –ø–æ –¥–µ–ª—É.
- –ù–µ –≤—ã–¥—É–º—ã–≤–∞–π —Ñ–∞–∫—Ç—ã. –ï—Å–ª–∏ –Ω–µ –∑–Ω–∞–µ—à—å ‚Äî —Å–∫–∞–∂–∏: "–õ—É—á—à–µ –æ–±—Å—É–¥–∏—Ç—å —ç—Ç–æ –ª–∏—á–Ω–æ —Å –ë–∞—Ö—Ç–∏—ë—Ä–æ–º, –æ—Å—Ç–∞–≤—å—Ç–µ –∑–∞—è–≤–∫—É".

–í–ê–ñ–ù–û: –¢—ã –æ–±—â–∞–µ—à—å—Å—è –≤ Telegram. –¢–≤–æ–∏ –æ—Ç–≤–µ—Ç—ã –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å –ª–µ–≥–∫–æ —á–∏—Ç–∞–µ–º—ã–º–∏ —Å —Ç–µ–ª–µ—Ñ–æ–Ω–∞.
"""

def setup_ai():
    """Initializes the AI model."""
    if not GEMINI_API_KEY:
        logger.warning("‚ö†Ô∏è GEMINI_API_KEY is missing. AI will not work.")
        return None
    
    try:
        genai.configure(api_key=GEMINI_API_KEY)
        
        # Try preferred models in order (updated based on API check)
        model_names = [
            'gemini-2.0-flash',
            'gemini-2.5-flash',
            'gemini-flash-latest',
            'gemini-pro'
        ]
        
        for name in model_names:
            try:
                # Note: 'system_instruction' is supported in newer versions (we have 0.8.6)
                # But some older models might reject it or the API endpoint might vary.
                # We try with it first.
                model = genai.GenerativeModel(name, system_instruction=SYSTEM_PROMPT)
                
                # CRITICAL: Test the model immediately. 
                # The constructor is lazy and won't throw 404. We must generate something.
                logger.info(f"Testing model: {name}...")
                model.generate_content("Test")
                
                logger.info(f"‚úÖ AI Successfully configured using: {name}")
                return model
            except Exception as e:
                logger.warning(f"‚ùå Model {name} failed: {e}")
                continue
        
        logger.error("‚ùå All AI models failed to initialize.")
        return None
    except Exception as e:
        logger.error(f"Failed to configure AI: {e}")
        return None

# Global model instance
model = setup_ai()

async def get_ai_response(user_text: str) -> str:
    """
    Generates a response using Google Gemini.
    """
    if not model:
        return "–ò–∑–≤–∏–Ω–∏—Ç–µ, –º–æ–π –∏—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω—ã–π –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç —Å–µ–π—á–∞—Å –æ—Ç–¥—ã—Ö–∞–µ—Ç (–Ω–µ—Ç –∫–ª—é—á–∞ API). üò¥\n–ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–∑–∂–µ –∏–ª–∏ –≤—ã–±–µ—Ä–∏—Ç–µ –ø—É–Ω–∫—Ç –≤ –º–µ–Ω—é."

    try:
        # Use simple generation for now. For context, we could use ChatSession but stateless is fine for simple Q&A.
        # To maintain context, we would need to store history per user. 
        # For MVP V2, let's keep it stateless (responds to the current message).
        response = await model.generate_content_async(user_text)
        return response.text
    except Exception as e:
        logger.error(f"AI Generation Error: {e}")
        return "–ß—Ç–æ-—Ç–æ –ø–æ—à–ª–æ –Ω–µ —Ç–∞–∫ —Å –º–æ–∏–º —ç–ª–µ–∫—Ç—Ä–æ–Ω–Ω—ã–º –º–æ–∑–≥–æ–º. ü§Ø\n–ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–µ—Ä–µ—Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∞—Ç—å –≤–æ–ø—Ä–æ—Å."
